---
job: extension
config:
  name: "adalora_alia_bhatt"
  process:
    - type: 'sd_trainer'
      training_folder: "/root/varunika/img/ai-toolkit/output"
      log_dir: "/root/varunika/img/ai-toolkit/output/adalora_alia_bhatt/tensorboard"
      device: cuda:1
      performance_log_every: 10

      network:
        type: "adalora"
        linear: 32 # Corresponds to `r` (max rank) in AdaLoraConfig (max rank for LoRA adapters)
        linear_alpha: 32 # Corresponds to `lora_alpha`
        lora_dropout: 0.0 # Dropout rate for AdaLoRA layers

        # AdaLoRA specific parameters (refer to peft.AdaLoraConfig)
        # These values are examples and might need tuning. The code will use `train.steps` for `total_step`.
        adalora_target_r: 8 # target_r: The target average rank of incremental matrix. (e.g., linear // 4)
        adalora_init_r: 32 # init_r: The initial rank for each incremental matrix. (e.g., linear)
        # tinit: Steps of initial fine-tuning warmup. (e.g., total_step // 4)
        adalora_tinit: 500 # If train.steps is 2000, this is 2000 // 4
        # tfinal: Number of steps of final fine-tuning. (e.g., 3 * total_step // 4)
        adalora_tfinal: 250 # If train.steps is 2000, this is 3 * 2000 // 4
        adalora_deltaT: 10 # deltaT: Time interval between two budget allocations.
        adalora_beta1: 0.85 # beta1: EMA parameter 1 for sensitivity smoothing.
        adalora_beta2: 0.85 # beta2: EMA parameter 2 for uncertainty quantification.
        adalora_orth_reg_weight: 0.5 # orth_reg_weight: Coefficient of orthogonal regularization.
        
        network_kwargs:
          only_if_contains: 
            - ".*attn.*" 

      save:
        dtype: bf16 
        save_every: 250
        max_step_saves_to_keep: 4 
        save_format: diffusers
        push_to_hub: false 

      datasets:
        - folder_path: "/root/varunika/img/datasets/datasets/alia_bhatt"
          trigger_token: '[AB]'
          initializer_concept: "A 34 year old Indian woman, 5 feet 1 inch tall, fair skin, slim build, slim jawline, dimples on cheeks"
          caption_ext: txt
          cache_latents_to_disk: false
          resolution:
          - 512
          - 768
          - 1024

      train:
        batch_size: 1
        steps: 2000
        gradient_accumulation: 2
        train_unet: true 
        train_text_encoder: false
        gradient_checkpointing: true 
        noise_scheduler: flowmatch
        optimizer: adamw8bit
        lr: 0.0001
        ema_config:
          use_ema: false
        dtype: bf16

      model:
        name_or_path: "Qwen/Qwen-Image" 
        quantize: false
        arch: qwen_image

      sample:
        sampler: flowmatch
        sample_every: 250
        width: 1664
        height: 928
        prompts:
          - "A close-up portrait of ([AB] woman) smiling, soft natural light, bokeh background."
          - "A full-body shot of ([AB] woman) walking in a bustling city street, vibrant atmosphere."
        neg: ''
        seed: 42
        guidance_scale: 4
        sample_steps: 25

meta:
  name: "adalora_alia_bhatt"
  version: '1.0'